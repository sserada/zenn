---
title: "[論文メモ] Humming2Music: Being A Composer As Long As You Can Humming"
emoji: "🎧"
type: "tech"
topics: [論文, 音楽]
published: false
---

# はじめに
本記事では，IJCAI 2023で発表された論文"Humming2Music: Being A Composer As Long As You Can Humming"の内容をまとめる．この論文では，鼻歌を入力として受け取り，それを元に完全な楽曲を自動生成するシステムを提案している．システムは5つのモジュールから構成されており，ユーザによって入力された鼻歌を楽譜に変換し，メロディを生成，伴奏を加え，最終的に音声合成を行う．提案システムは，音楽の専門知識がないユーザでも簡単に楽曲を作成できることを目指している．

https://www.ijcai.org/proceedings/2023/840

# Introduction
近年，音楽生成技術は急速に進歩しており，多くの手法が提案されいている．ユーザの入力に基づいてカスタマイズされた楽曲を生成する技術も提案されているが，歌詞やコード進行に基づくものが多く，よりユーザが直感的に入力可能な鼻歌に基づく生成技術は未だ少ない．さらに，既存の鼻歌による入力をサポートする手法は，鼻歌から伴奏の生成のみを行うため，ユーザが完全なメロディを鼻歌で入力する必要がありハードルが高い．

そこで，本研究では鼻歌を入力として受け取り，それを元に完全な楽曲を自動生成するシステムを提案している．このシステムは，音楽知識がないユーザでも簡単に楽曲を作成できることを目指している．システムは5つのモジュールから構成されており，それぞれの役割は以下の通りである．
1. **鼻歌の楽譜変換 (Humming Transcription)**: ユーザの入力した鼻歌を楽譜（MIDI形式）に変換する．このプロセスでは，YOLOXモデルを使用して，鼻歌をスペクトログラム画像として解析して音符に変換する．
2. **メロディ生成 (Melody Generation)**: 変換された鼻歌のメロディを元に完全なメロディを生成する．生成はテンプレートマッチングに基づき，コードやリズムのテンプレートを使用してメロディを補完する．
3. **分散和音生成 (Broken Chord Generation)**: 生成されたメロディに対して，分散和音を生成し，表現力を加える．Transformerベースのモデルを使用して，メロディとコードに基づく分散和音を生成する．
4. **伴奏生成 (Accompaniment Generatio)**: ドラム，ベース，ストリングスなどの追加伴奏トラックを生成し，音楽全体を補完する．ルールベースの音楽理論を使用して，リズムやコードに合わせた伴奏を生成する．
5. **音声合成 (Audio Synthesis)**: 全てのトラックをミックスし，適切な音量バランスやエフェクト（リバーブ，コンプレッサなど）を加えて，最終的な音楽を合成する．

上記のモジュールを通して，ユーザの鼻歌から質の高い楽曲を生成することが可能となる．