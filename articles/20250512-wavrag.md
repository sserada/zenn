---
title: "[論文] 音声をテキスト変換なしで直接AI処理！WavRAGの論文要約"
emoji: "🌊"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: [論文, 音声, RAG]
published: false
---

## はじめに
本記事では、音声をネイティブに処理する検索拡張生成(Retrieval Augmented Generation: RAG)フレームワークを提案している論文"[WavRAG: Audio-Integrated Retrieval Augmented Generation for Spoken Dialogue Models](https://arxiv.org/abs/2502.14727)"の内容をまとめています。WavRAGは、音声認識(ASR)を介さずに生の音声を直接処理し、音声とテキストのハイブリッド知識ベースからの検索を可能にする初のRAGフレームワークです。特に、音声埋め込みと検索を直接処理するWavRetrieverと、思考連鎖（Chain-of-Thought）推論による音声対話モデルのコンテキスト内能力強化が特徴です。従来のASR-テキストRAGパイプラインと比較して同等の検索性能を維持しながら、処理速度を平均10倍に高速化しています。

https://arxiv.org/abs/2502.14727

## 背景と課題
検索拡張生成（RAG）は、大規模言語モデル（LLM）が外部の知識を取り込めるようにする技術として、自然言語処理の分野で広く採用されています。しかし、これまでのRAGフレームワークは、主にテキスト向けに設計されており、音声を扱うときには音声認識（ASR）を介してテキストに変換する必要がありました。
この従来のアプローチには、いくつかの問題点があります:
- **音声情報の損失**: 音声をテキストに変換することで、声のトーンや感情、周囲の環境音などの情報が失われる
- **ASRの精度依存**: ASRが誤認識を起こすと、後続の処理にも悪影響を及ぼす
- **処理速度の低下**: ASRを介することで、全体の処理速度が遅くなる
- **テキスト偏重**: 音声特有の知識（環境音や音楽など）を活かせない
特に音声には、人の話し声だけでなく、環境音や音楽、動物の鳴き声など、ASRでは捉えきれない情報が含まれています。こうした音声情報をそのまま扱える技術が求められていました。

こうした課題に対して、著者らはWavRAGという新しいRAGフレームワークを提案しています。主な特徴は以下の通りです:
- **音声をそのまま処理**: ASRを介さず、音声を直接処理して埋め込みや検索を行う
- **音声とテキストの統合**: 両方のデータを同じ知識表現空間で扱う
- **WavRetriever**: Qwen2-Audioという音声理解に強いモデルをベースに、対照学習で訓練した検索エンジンを開発
- **思考連鎖による推論**: 検索した情報を論理的に組み立てて処理する仕組みを導入し、回答の信頼性を向上